{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e026bde-af46-4d38-a00b-634fa430498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from legiscan import LegiScan\n",
    "import legiscan\n",
    "import fetch_data\n",
    "import os\n",
    "import pandas as pd\n",
    "import swifter\n",
    "import zipfile\n",
    "import base64\n",
    "import io\n",
    "import glob\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import mimetypes\n",
    "import tqdm \n",
    "\n",
    "from importlib import reload\n",
    "reload(legiscan);\n",
    "reload(fetch_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b7ebcb1-51e1-4a06-b2a2-f7dd9f1c6ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FetchData: \n",
    "    \n",
    "    PATH_OUTPUT = './sample-data-2/'\n",
    "    \n",
    "    def __init__(self, \n",
    "                 api_key \n",
    "                 ): \n",
    "        self.api_key = api_key\n",
    "        self.legis = LegiScan()\n",
    "        self.__test_dataset__()\n",
    "        self.find_json()\n",
    "        self.process_json()\n",
    "        self.create_dataframe()\n",
    "        self.df_to_csv()\n",
    "        \n",
    "        \n",
    "    def check_directories(self): \n",
    "        if not os.path.exists(self.PATH_OUTPUT): \n",
    "            os.mkdir(self.PATH_OUTPUT)\n",
    "        return\n",
    "        \n",
    "    def __test_dataset__(self): \n",
    "        self.__datasets = legis.get_dataset_list()\n",
    "        self.__dataset = legis.get_dataset(datasets[20]['session_id'], datasets[20]['access_key'])\n",
    "        return \n",
    "        \n",
    "    def get_test_dataset(self): \n",
    "        return self.__dataset.copy()\n",
    "    \n",
    "    def decode_test_dataset(self): \n",
    "        # we need to decode the datasets into a normal file, using Python's zipfile module here\n",
    "        dataset = self.__test_dataset__()\n",
    "        __z_bytes__ = base64.b64decode(dataset['zip'])\n",
    "\n",
    "        # create an in-memory stream for bytes data (io.BytesIO()) from decoded base64,\n",
    "        #     then create a zipfile object using the zipfile module to store the bytes\n",
    "        __z__ = zipfile.ZipFile(io.BytesIO(__z_bytes__))\n",
    "\n",
    "        # extract all files in the zip file\n",
    "        __z__.extractall(PATH_OUTPUT)\n",
    "        return\n",
    "        \n",
    "    def find_json(self): \n",
    "        filenames = glob.glob(\"bill_data/*/*/bill/*.json\")\n",
    "        return filenames\n",
    "    \n",
    "    def get_json_filenames(self): \n",
    "        return self.find_json()\n",
    "        \n",
    "    def process_json(self):\n",
    "        with open(filename) as file:\n",
    "            bill_data = {}\n",
    "            # We need to do a little string replacing so the \n",
    "            json_str = file.read().replace('\"0000-00-00\"', 'null')\n",
    "            content = json.loads(json_str)['bill']\n",
    "\n",
    "            bill_data['bill_id'] = content['bill_id']\n",
    "            bill_data['code'] = os.path.splitext(os.path.basename(filename))[0]\n",
    "            bill_data['bill_number'] = content['bill_number']\n",
    "            bill_data['title'] = content['title']\n",
    "            bill_data['description'] = content['description']\n",
    "            bill_data['state'] = content['state']\n",
    "            bill_data['session'] = content['session']['session_name']\n",
    "            bill_data['filename'] = filename\n",
    "            bill_data['status'] = content['status']\n",
    "            bill_data['status_date'] = content['status_date']\n",
    "\n",
    "            try:\n",
    "                bill_data['url'] = content['texts'][-1]['state_link']\n",
    "            except:\n",
    "                pass\n",
    "            return pd.Series(bill_data)\n",
    "        \n",
    "        def create_dataframe(self): \n",
    "            df = pd.Series(self.get_json).swifter.apply(self.process_json)\n",
    "            return\n",
    "        \n",
    "        def get_dataframe(self): \n",
    "            return self.create_dataframe()\n",
    "        \n",
    "        def df_to_csv(self): \n",
    "            df.to_csv('PATH_OUTPUT' + '/bills-with-urls.csv', index=False)\n",
    "            return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3648074-b80a-4944-8f93-f085dcf6f378",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FetchData: \n",
    "    \n",
    "    PATH_OUTPUT = './sample-data-2/'\n",
    "    \n",
    "    def __init__(self\n",
    "                 ): \n",
    "        self.api_key = os.environ.get('LEGISCAN_API_KEY')\n",
    "        self.legis = LegiScan(self.api_key)\n",
    "        self.__test_dataset__()\n",
    "        self.find_json()\n",
    "        self.process_json()\n",
    "        self.create_dataframe()\n",
    "        self.df_to_csv()\n",
    "        \n",
    "        \n",
    "    def check_directories(self): \n",
    "        if not os.path.exists(self.PATH_OUTPUT): \n",
    "            os.mkdir(self.PATH_OUTPUT)\n",
    "        return\n",
    "        \n",
    "    def __test_dataset__(self): \n",
    "        self.__datasets = legis.get_dataset_list()\n",
    "        self.__dataset = legis.get_dataset(datasets[20]['session_id'], datasets[20]['access_key'])\n",
    "        return \n",
    "        \n",
    "    def get_test_dataset(self): \n",
    "        return self.__dataset.copy()\n",
    "    \n",
    "    def decode_test_dataset(self): \n",
    "        # we need to decode the datasets into a normal file, using Python's zipfile module here\n",
    "        dataset = self.__test_dataset__()\n",
    "        __z_bytes__ = base64.b64decode(dataset['zip'])\n",
    "\n",
    "        # create an in-memory stream for bytes data (io.BytesIO()) from decoded base64,\n",
    "        #     then create a zipfile object using the zipfile module to store the bytes\n",
    "        __z__ = zipfile.ZipFile(io.BytesIO(__z_bytes__))\n",
    "\n",
    "        # extract all files in the zip file\n",
    "        __z__.extractall(PATH_OUTPUT)\n",
    "        return\n",
    "        \n",
    "    def find_json(self): \n",
    "        filenames = glob.glob(\"bill_data/*/*/bill/*.json\")\n",
    "        return filenames\n",
    "    \n",
    "    def get_json_filenames(self): \n",
    "        return self.find_json()\n",
    "        \n",
    "    def process_json(self):\n",
    "        with open(filename) as file:\n",
    "            bill_data = {}\n",
    "            # We need to do a little string replacing so the \n",
    "            json_str = file.read().replace('\"0000-00-00\"', 'null')\n",
    "            content = json.loads(json_str)['bill']\n",
    "\n",
    "            bill_data['bill_id'] = content['bill_id']\n",
    "            bill_data['code'] = os.path.splitext(os.path.basename(filename))[0]\n",
    "            bill_data['bill_number'] = content['bill_number']\n",
    "            bill_data['title'] = content['title']\n",
    "            bill_data['description'] = content['description']\n",
    "            bill_data['state'] = content['state']\n",
    "            bill_data['session'] = content['session']['session_name']\n",
    "            bill_data['filename'] = filename\n",
    "            bill_data['status'] = content['status']\n",
    "            bill_data['status_date'] = content['status_date']\n",
    "\n",
    "            try:\n",
    "                bill_data['url'] = content['texts'][-1]['state_link']\n",
    "            except:\n",
    "                pass\n",
    "            return pd.Series(bill_data)\n",
    "        \n",
    "        def create_dataframe(self): \n",
    "            df = pd.Series(self.get_json).swifter.apply(self.process_json)\n",
    "            return\n",
    "        \n",
    "        def get_dataframe(self): \n",
    "            return self.create_dataframe()\n",
    "        \n",
    "        def df_to_csv(self): \n",
    "            df.to_csv('PATH_OUTPUT' + '/bills-with-urls.csv', index=False)\n",
    "            return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef380411-79d6-44b8-a5ab-011f196200bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'api_key'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fd \u001b[38;5;241m=\u001b[39m \u001b[43mFetchData\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'api_key'"
     ]
    }
   ],
   "source": [
    "fd = FetchData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0549496f-3f2c-4303-b7e8-e69cd96ab376",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
